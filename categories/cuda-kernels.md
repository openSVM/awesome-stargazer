[â† Previous: Cuda Deep Learning](cuda-deep-learning.txt) | [ğŸ  Back to README](../README.md) | [Next: Cuda Other 1 â†’](cuda-other-1.txt)

---

# CUDA KERNELS

**12 repositories**

---

## [xlite-dev/LeetCUDA](https://github.com/xlite-dev/LeetCUDA)

ğŸ“šLeetCUDA: Modern CUDA Learn Notes with PyTorch for BeginnersğŸ‘, 200+ CUDA Kernels, Tensor Cores, HGEMM, FA-2 MMA.ğŸ‰

ğŸ”— [https://github.com/xlite-dev/LeetCUDA](https://github.com/xlite-dev/LeetCUDA)

---

## [zhihu/cuBERT](https://github.com/zhihu/cuBERT)

Fast implementation of BERT inference directly on NVIDIA (CUDA, CUBLAS) and Intel MKL

ğŸ”— [https://github.com/zhihu/cuBERT](https://github.com/zhihu/cuBERT)

---

## [Liu-xiandong/How_to_optimize_in_GPU](https://github.com/Liu-xiandong/How_to_optimize_in_GPU)

This is a series of GPU optimization topics. Here we will introduce  how to optimize the CUDA kernel in detail.  I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.

ğŸ”— [https://github.com/Liu-xiandong/How_to_optimize_in_GPU](https://github.com/Liu-xiandong/How_to_optimize_in_GPU)

---

## [SparseLinearAlgebra/cuBool](https://github.com/SparseLinearAlgebra/cuBool)

Sparse linear Boolean algebra for Nvidia Cuda

ğŸ”— [https://github.com/SparseLinearAlgebra/cuBool](https://github.com/SparseLinearAlgebra/cuBool)

---

## [NVIDIA/nvbench](https://github.com/NVIDIA/nvbench)

CUDA Kernel Benchmarking Library

ğŸ”— [https://github.com/NVIDIA/nvbench](https://github.com/NVIDIA/nvbench)

---

## [xiaziyna/CUDA-transit-detection](https://github.com/xiaziyna/CUDA-transit-detection)

GPU CUDA kernel for exoplanet transit detection

ğŸ”— [https://github.com/xiaziyna/CUDA-transit-detection](https://github.com/xiaziyna/CUDA-transit-detection)

---

## [NVIDIA/thrust](https://github.com/NVIDIA/thrust)

[ARCHIVED] The C++ parallel algorithms library. See https://github.com/NVIDIA/cccl

ğŸ”— [https://github.com/NVIDIA/thrust](https://github.com/NVIDIA/thrust)

---

## [je-suis-tm/quant-trading](https://github.com/je-suis-tm/quant-trading)

Python quantitative trading strategies including VIX Calculator, Pattern Recognition, Commodity Trading Advisor, Monte Carlo, Options Straddle, Shooting Star, London Breakout, Heikin-Ashi, Pair Trading, RSI, Bollinger Bands, Parabolic SAR, Dual Thrust, Awesome, MACD

ğŸ”— [https://github.com/je-suis-tm/quant-trading](https://github.com/je-suis-tm/quant-trading)

---

## [Zlisch/LargeMM](https://github.com/Zlisch/LargeMM)

A CUBLASâ€CUDA Based Implementation of Multi-GPU Large Matrix Multiplication

ğŸ”— [https://github.com/Zlisch/LargeMM](https://github.com/Zlisch/LargeMM)

---

## [dc-fukuoka/gpumm](https://github.com/dc-fukuoka/gpumm)

gpumm -  matrix-matrix multiplication by using CUDA, cublas, cublasxt and OpenACC.

ğŸ”— [https://github.com/dc-fukuoka/gpumm](https://github.com/dc-fukuoka/gpumm)

---

## [MarcoGarlet/CUDA_CubeAttack](https://github.com/MarcoGarlet/CUDA_CubeAttack)

CUDA implementation of Cube Attack

ğŸ”— [https://github.com/MarcoGarlet/CUDA_CubeAttack](https://github.com/MarcoGarlet/CUDA_CubeAttack)

---

## [NVIDIA/cub](https://github.com/NVIDIA/cub)

[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl

ğŸ”— [https://github.com/NVIDIA/cub](https://github.com/NVIDIA/cub)

---


[â† Previous: Cuda Deep Learning](cuda-deep-learning.txt) | [ğŸ  Back to README](../README.md) | [Next: Cuda Other 1 â†’](cuda-other-1.txt)
