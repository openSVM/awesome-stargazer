[← Previous: Cuda Deep Learning](cuda-deep-learning.txt) | [🏠 Back to README](../README.md) | [Next: Cuda Other 1 →](cuda-other-1.txt)

---

# CUDA KERNELS

**12 repositories**

---

## [xlite-dev/LeetCUDA](https://github.com/xlite-dev/LeetCUDA)

📚LeetCUDA: Modern CUDA Learn Notes with PyTorch for Beginners🐑, 200+ CUDA Kernels, Tensor Cores, HGEMM, FA-2 MMA.🎉

🔗 [https://github.com/xlite-dev/LeetCUDA](https://github.com/xlite-dev/LeetCUDA)

---

## [zhihu/cuBERT](https://github.com/zhihu/cuBERT)

Fast implementation of BERT inference directly on NVIDIA (CUDA, CUBLAS) and Intel MKL

🔗 [https://github.com/zhihu/cuBERT](https://github.com/zhihu/cuBERT)

---

## [Liu-xiandong/How_to_optimize_in_GPU](https://github.com/Liu-xiandong/How_to_optimize_in_GPU)

This is a series of GPU optimization topics. Here we will introduce  how to optimize the CUDA kernel in detail.  I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.

🔗 [https://github.com/Liu-xiandong/How_to_optimize_in_GPU](https://github.com/Liu-xiandong/How_to_optimize_in_GPU)

---

## [SparseLinearAlgebra/cuBool](https://github.com/SparseLinearAlgebra/cuBool)

Sparse linear Boolean algebra for Nvidia Cuda

🔗 [https://github.com/SparseLinearAlgebra/cuBool](https://github.com/SparseLinearAlgebra/cuBool)

---

## [NVIDIA/nvbench](https://github.com/NVIDIA/nvbench)

CUDA Kernel Benchmarking Library

🔗 [https://github.com/NVIDIA/nvbench](https://github.com/NVIDIA/nvbench)

---

## [xiaziyna/CUDA-transit-detection](https://github.com/xiaziyna/CUDA-transit-detection)

GPU CUDA kernel for exoplanet transit detection

🔗 [https://github.com/xiaziyna/CUDA-transit-detection](https://github.com/xiaziyna/CUDA-transit-detection)

---

## [NVIDIA/thrust](https://github.com/NVIDIA/thrust)

[ARCHIVED] The C++ parallel algorithms library. See https://github.com/NVIDIA/cccl

🔗 [https://github.com/NVIDIA/thrust](https://github.com/NVIDIA/thrust)

---

## [je-suis-tm/quant-trading](https://github.com/je-suis-tm/quant-trading)

Python quantitative trading strategies including VIX Calculator, Pattern Recognition, Commodity Trading Advisor, Monte Carlo, Options Straddle, Shooting Star, London Breakout, Heikin-Ashi, Pair Trading, RSI, Bollinger Bands, Parabolic SAR, Dual Thrust, Awesome, MACD

🔗 [https://github.com/je-suis-tm/quant-trading](https://github.com/je-suis-tm/quant-trading)

---

## [Zlisch/LargeMM](https://github.com/Zlisch/LargeMM)

A CUBLAS‐CUDA Based Implementation of Multi-GPU Large Matrix Multiplication

🔗 [https://github.com/Zlisch/LargeMM](https://github.com/Zlisch/LargeMM)

---

## [dc-fukuoka/gpumm](https://github.com/dc-fukuoka/gpumm)

gpumm -  matrix-matrix multiplication by using CUDA, cublas, cublasxt and OpenACC.

🔗 [https://github.com/dc-fukuoka/gpumm](https://github.com/dc-fukuoka/gpumm)

---

## [MarcoGarlet/CUDA_CubeAttack](https://github.com/MarcoGarlet/CUDA_CubeAttack)

CUDA implementation of Cube Attack

🔗 [https://github.com/MarcoGarlet/CUDA_CubeAttack](https://github.com/MarcoGarlet/CUDA_CubeAttack)

---

## [NVIDIA/cub](https://github.com/NVIDIA/cub)

[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl

🔗 [https://github.com/NVIDIA/cub](https://github.com/NVIDIA/cub)

---


[← Previous: Cuda Deep Learning](cuda-deep-learning.txt) | [🏠 Back to README](../README.md) | [Next: Cuda Other 1 →](cuda-other-1.txt)
