[â† Previous: Rl Algorithms](rl-algorithms.txt) | [ğŸ  Back to README](../README.md) | [Next: Rl Frameworks â†’](rl-frameworks.txt)

---

# RL ENVIRONMENTS

**25 repositories**

---

## [GPUOpen-LibrariesAndSDKs/Schola](https://github.com/GPUOpen-LibrariesAndSDKs/Schola)

Schola is a plugin for enabling Reinforcement Learning (RL) in Unreal Engine. It provides tools to help developers create environments, define agents, and connect to python-based RL frameworks such as OpenAI Gym, RLlib or Stable Baselines 3 for training agents with RL.

ğŸ”— [https://github.com/GPUOpen-LibrariesAndSDKs/Schola](https://github.com/GPUOpen-LibrariesAndSDKs/Schola)

---

## [google-deepmind/open_spiel](https://github.com/google-deepmind/open_spiel)

OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games.

ğŸ”— [https://github.com/google-deepmind/open_spiel](https://github.com/google-deepmind/open_spiel)

---

## [xlang-ai/OSWorld](https://github.com/xlang-ai/OSWorld)

[NeurIPS 2024] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments

ğŸ”— [https://github.com/xlang-ai/OSWorld](https://github.com/xlang-ai/OSWorld)

---

## [solplayground/solana_gym](https://github.com/solplayground/solana_gym)

OpenAI Gym Environment for Trading on Solana blockchain

ğŸ”— [https://github.com/solplayground/solana_gym](https://github.com/solplayground/solana_gym)

---

## [KhoomeiK/LlamaGym](https://github.com/KhoomeiK/LlamaGym)

Fine-tune LLM agents with online reinforcement learning

ğŸ”— [https://github.com/KhoomeiK/LlamaGym](https://github.com/KhoomeiK/LlamaGym)

---

## [PufferAI/PufferLib](https://github.com/PufferAI/PufferLib)

Simplifying reinforcement learning for complex game environments

ğŸ”— [https://github.com/PufferAI/PufferLib](https://github.com/PufferAI/PufferLib)

---

## [Miyamura80/tinyAcceleratedEVM](https://github.com/Miyamura80/tinyAcceleratedEVM)

A gymnax based EVM simulator written in the JAX machine learning framework. The idea is to write an EVM simulator that can be parallelized and gain significant performance boosts on the accelerated hardware such GPU/TPU.

ğŸ”— [https://github.com/Miyamura80/tinyAcceleratedEVM](https://github.com/Miyamura80/tinyAcceleratedEVM)

---

## [a16z-infra/JungleGym](https://github.com/a16z-infra/JungleGym)

An Open Source Playground with Agent Datasets and APIs for building and testing your own Autonomous Web Agents

ğŸ”— [https://github.com/a16z-infra/JungleGym](https://github.com/a16z-infra/JungleGym)

---

## [harveybc/gym-fx](https://github.com/harveybc/gym-fx)

Forex trading simulator environment for OpenAI Gym, observations contain the order status, performance and timeseries loaded from a CSV file containing rates and indicators. Work In Progress

ğŸ”— [https://github.com/harveybc/gym-fx](https://github.com/harveybc/gym-fx)

---

## [sail-sg/envpool](https://github.com/sail-sg/envpool)

C++-based high-performance parallel environment execution engine (vectorized env) for general RL environments.

ğŸ”— [https://github.com/sail-sg/envpool](https://github.com/sail-sg/envpool)

---

## [cocktailpeanut/fluxgym](https://github.com/cocktailpeanut/fluxgym)

Dead simple FLUX LoRA training UI with LOW VRAM support

ğŸ”— [https://github.com/cocktailpeanut/fluxgym](https://github.com/cocktailpeanut/fluxgym)

---

## [Yvictor/TradingGym](https://github.com/Yvictor/TradingGym)

Trading and Backtesting environment for training reinforcement learning agent or simple rule base algo.

ğŸ”— [https://github.com/Yvictor/TradingGym](https://github.com/Yvictor/TradingGym)

---

## [charlieroberts/wgsl_live](https://github.com/charlieroberts/wgsl_live)

An environment for live coding fragment shaders using WGSL

ğŸ”— [https://github.com/charlieroberts/wgsl_live](https://github.com/charlieroberts/wgsl_live)

---

## [ChuaCheowHuan/gym-continuousDoubleAuction](https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction)

A custom MARL (multi-agent reinforcement learning) environment where multiple agents trade against one another (self-play) in a zero-sum continuous double auction. Ray [RLlib] is used for training.

ğŸ”— [https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction](https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction)

---

## [AminHP/gym-anytrading](https://github.com/AminHP/gym-anytrading)

The most simple, flexible, and comprehensive OpenAI Gym trading environment (Approved by OpenAI Gym)

ğŸ”— [https://github.com/AminHP/gym-anytrading](https://github.com/AminHP/gym-anytrading)

---

## [barkerbg001/echo-valley](https://github.com/barkerbg001/echo-valley)

Echo Valley is a procedurally generated 3D environment built with WebGL and Three.js. It offers an expansive, evolving world for exploration and experimentation, showcasing procedural generation in 3D. Whether you're a developer or just love endless virtual spaces, Echo Valley is a captivating sandbox to explore.

ğŸ”— [https://github.com/barkerbg001/echo-valley](https://github.com/barkerbg001/echo-valley)

---

## [openai/retro](https://github.com/openai/retro)

Retro Games in Gym

ğŸ”— [https://github.com/openai/retro](https://github.com/openai/retro)

---

## [gavento/gamegym](https://github.com/gavento/gamegym)

A game theory framework with examples and algorithms

ğŸ”— [https://github.com/gavento/gamegym](https://github.com/gavento/gamegym)

---

## [nadavbh12/Retro-Learning-Environment](https://github.com/nadavbh12/Retro-Learning-Environment)

The Retro Learning Environment (RLE) -- a learning framework for AI

ğŸ”— [https://github.com/nadavbh12/Retro-Learning-Environment](https://github.com/nadavbh12/Retro-Learning-Environment)

---

## [pearl-core/pearl](https://github.com/pearl-core/pearl)

Pearl is a lightweight package manager for automating reproducible environments between different systems (Linux and OSX). It can be used for dotfiles, plugins, programs and any form of code accessible via git.

ğŸ”— [https://github.com/pearl-core/pearl](https://github.com/pearl-core/pearl)

---

## [marlinprotocol/oyster-serverless](https://github.com/marlinprotocol/oyster-serverless)

Oyster Serverless is a cutting-edge, high-performance serverless computing platform designed to securely execute JavaScript (JS) and WebAssembly (WASM) code in a highly controlled environment.

ğŸ”— [https://github.com/marlinprotocol/oyster-serverless](https://github.com/marlinprotocol/oyster-serverless)

---

## [InseeFrLab/onyxia](https://github.com/InseeFrLab/onyxia)

ğŸ”¬ Data science environment for k8s

ğŸ”— [https://github.com/InseeFrLab/onyxia](https://github.com/InseeFrLab/onyxia)

---

## [facebookresearch/CompilerGym](https://github.com/facebookresearch/CompilerGym)

Reinforcement learning environments for compiler and program optimization tasks

ğŸ”— [https://github.com/facebookresearch/CompilerGym](https://github.com/facebookresearch/CompilerGym)

---

## [e2b-dev/E2B](https://github.com/e2b-dev/E2B)

Open-source, secure environment with real-world tools for enterprise-grade agents.

ğŸ”— [https://github.com/e2b-dev/E2B](https://github.com/e2b-dev/E2B)

---


[â† Previous: Rl Algorithms](rl-algorithms.txt) | [ğŸ  Back to README](../README.md) | [Next: Rl Frameworks â†’](rl-frameworks.txt)
