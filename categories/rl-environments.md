[← Previous: Rl Algorithms](rl-algorithms.txt) | [🏠 Back to README](../README.md) | [Next: Rl Frameworks →](rl-frameworks.txt)

---

# RL ENVIRONMENTS

**25 repositories**

---

## [GPUOpen-LibrariesAndSDKs/Schola](https://github.com/GPUOpen-LibrariesAndSDKs/Schola)

Schola is a plugin for enabling Reinforcement Learning (RL) in Unreal Engine. It provides tools to help developers create environments, define agents, and connect to python-based RL frameworks such as OpenAI Gym, RLlib or Stable Baselines 3 for training agents with RL.

🔗 [https://github.com/GPUOpen-LibrariesAndSDKs/Schola](https://github.com/GPUOpen-LibrariesAndSDKs/Schola)

---

## [google-deepmind/open_spiel](https://github.com/google-deepmind/open_spiel)

OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games.

🔗 [https://github.com/google-deepmind/open_spiel](https://github.com/google-deepmind/open_spiel)

---

## [xlang-ai/OSWorld](https://github.com/xlang-ai/OSWorld)

[NeurIPS 2024] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments

🔗 [https://github.com/xlang-ai/OSWorld](https://github.com/xlang-ai/OSWorld)

---

## [solplayground/solana_gym](https://github.com/solplayground/solana_gym)

OpenAI Gym Environment for Trading on Solana blockchain

🔗 [https://github.com/solplayground/solana_gym](https://github.com/solplayground/solana_gym)

---

## [KhoomeiK/LlamaGym](https://github.com/KhoomeiK/LlamaGym)

Fine-tune LLM agents with online reinforcement learning

🔗 [https://github.com/KhoomeiK/LlamaGym](https://github.com/KhoomeiK/LlamaGym)

---

## [PufferAI/PufferLib](https://github.com/PufferAI/PufferLib)

Simplifying reinforcement learning for complex game environments

🔗 [https://github.com/PufferAI/PufferLib](https://github.com/PufferAI/PufferLib)

---

## [Miyamura80/tinyAcceleratedEVM](https://github.com/Miyamura80/tinyAcceleratedEVM)

A gymnax based EVM simulator written in the JAX machine learning framework. The idea is to write an EVM simulator that can be parallelized and gain significant performance boosts on the accelerated hardware such GPU/TPU.

🔗 [https://github.com/Miyamura80/tinyAcceleratedEVM](https://github.com/Miyamura80/tinyAcceleratedEVM)

---

## [a16z-infra/JungleGym](https://github.com/a16z-infra/JungleGym)

An Open Source Playground with Agent Datasets and APIs for building and testing your own Autonomous Web Agents

🔗 [https://github.com/a16z-infra/JungleGym](https://github.com/a16z-infra/JungleGym)

---

## [harveybc/gym-fx](https://github.com/harveybc/gym-fx)

Forex trading simulator environment for OpenAI Gym, observations contain the order status, performance and timeseries loaded from a CSV file containing rates and indicators. Work In Progress

🔗 [https://github.com/harveybc/gym-fx](https://github.com/harveybc/gym-fx)

---

## [sail-sg/envpool](https://github.com/sail-sg/envpool)

C++-based high-performance parallel environment execution engine (vectorized env) for general RL environments.

🔗 [https://github.com/sail-sg/envpool](https://github.com/sail-sg/envpool)

---

## [cocktailpeanut/fluxgym](https://github.com/cocktailpeanut/fluxgym)

Dead simple FLUX LoRA training UI with LOW VRAM support

🔗 [https://github.com/cocktailpeanut/fluxgym](https://github.com/cocktailpeanut/fluxgym)

---

## [Yvictor/TradingGym](https://github.com/Yvictor/TradingGym)

Trading and Backtesting environment for training reinforcement learning agent or simple rule base algo.

🔗 [https://github.com/Yvictor/TradingGym](https://github.com/Yvictor/TradingGym)

---

## [charlieroberts/wgsl_live](https://github.com/charlieroberts/wgsl_live)

An environment for live coding fragment shaders using WGSL

🔗 [https://github.com/charlieroberts/wgsl_live](https://github.com/charlieroberts/wgsl_live)

---

## [ChuaCheowHuan/gym-continuousDoubleAuction](https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction)

A custom MARL (multi-agent reinforcement learning) environment where multiple agents trade against one another (self-play) in a zero-sum continuous double auction. Ray [RLlib] is used for training.

🔗 [https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction](https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction)

---

## [AminHP/gym-anytrading](https://github.com/AminHP/gym-anytrading)

The most simple, flexible, and comprehensive OpenAI Gym trading environment (Approved by OpenAI Gym)

🔗 [https://github.com/AminHP/gym-anytrading](https://github.com/AminHP/gym-anytrading)

---

## [barkerbg001/echo-valley](https://github.com/barkerbg001/echo-valley)

Echo Valley is a procedurally generated 3D environment built with WebGL and Three.js. It offers an expansive, evolving world for exploration and experimentation, showcasing procedural generation in 3D. Whether you're a developer or just love endless virtual spaces, Echo Valley is a captivating sandbox to explore.

🔗 [https://github.com/barkerbg001/echo-valley](https://github.com/barkerbg001/echo-valley)

---

## [openai/retro](https://github.com/openai/retro)

Retro Games in Gym

🔗 [https://github.com/openai/retro](https://github.com/openai/retro)

---

## [gavento/gamegym](https://github.com/gavento/gamegym)

A game theory framework with examples and algorithms

🔗 [https://github.com/gavento/gamegym](https://github.com/gavento/gamegym)

---

## [nadavbh12/Retro-Learning-Environment](https://github.com/nadavbh12/Retro-Learning-Environment)

The Retro Learning Environment (RLE) -- a learning framework for AI

🔗 [https://github.com/nadavbh12/Retro-Learning-Environment](https://github.com/nadavbh12/Retro-Learning-Environment)

---

## [pearl-core/pearl](https://github.com/pearl-core/pearl)

Pearl is a lightweight package manager for automating reproducible environments between different systems (Linux and OSX). It can be used for dotfiles, plugins, programs and any form of code accessible via git.

🔗 [https://github.com/pearl-core/pearl](https://github.com/pearl-core/pearl)

---

## [marlinprotocol/oyster-serverless](https://github.com/marlinprotocol/oyster-serverless)

Oyster Serverless is a cutting-edge, high-performance serverless computing platform designed to securely execute JavaScript (JS) and WebAssembly (WASM) code in a highly controlled environment.

🔗 [https://github.com/marlinprotocol/oyster-serverless](https://github.com/marlinprotocol/oyster-serverless)

---

## [InseeFrLab/onyxia](https://github.com/InseeFrLab/onyxia)

🔬 Data science environment for k8s

🔗 [https://github.com/InseeFrLab/onyxia](https://github.com/InseeFrLab/onyxia)

---

## [facebookresearch/CompilerGym](https://github.com/facebookresearch/CompilerGym)

Reinforcement learning environments for compiler and program optimization tasks

🔗 [https://github.com/facebookresearch/CompilerGym](https://github.com/facebookresearch/CompilerGym)

---

## [e2b-dev/E2B](https://github.com/e2b-dev/E2B)

Open-source, secure environment with real-world tools for enterprise-grade agents.

🔗 [https://github.com/e2b-dev/E2B](https://github.com/e2b-dev/E2B)

---


[← Previous: Rl Algorithms](rl-algorithms.txt) | [🏠 Back to README](../README.md) | [Next: Rl Frameworks →](rl-frameworks.txt)
