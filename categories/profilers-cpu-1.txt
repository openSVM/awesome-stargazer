# PROFILERS CPU 1 (90 repositories)

reececomo/tinybuf: ‚ö°Ô∏è High-performance in-memory binary serializer for Node.js / HTML5 - https://github.com/reececomo/tinybuf
bytedance/web-bench: Web-Bench is a benchmark designed to evaluate the performance of LLMs in actual Web development.  - https://github.com/bytedance/web-bench
jd-opensource/xllm: A high-performance inference engine for LLMs, optimized for diverse AI accelerators. - https://github.com/jd-opensource/xllm
PaddlePaddle/FlyCV: FlyCV is a high-performance library for processing computer visual tasks.  - https://github.com/PaddlePaddle/FlyCV
arkflow-rs/arkflow: High performance Rust stream processing engine seamlessly integrates AI capabilities, providing powerful real-time data processing and intelligent analysis.  - https://github.com/arkflow-rs/arkflow
vxcontrol/pentagi: ‚ú® Fully autonomous AI Agents system capable of performing complex penetration testing tasks - https://github.com/vxcontrol/pentagi
tensorflow/serving: A flexible, high-performance serving system for machine learning models - https://github.com/tensorflow/serving
0xrinegade/Suspicion-Agent: The implementation of "Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4" - https://github.com/0xrinegade/Suspicion-Agent
cocoindex-io/cocoindex: Data transformation framework for AI. Ultra performant, with incremental processing. - https://github.com/cocoindex-io/cocoindex
PaddlePaddle/Paddle-Lite: PaddlePaddle High Performance Deep Learning Inference Engine for Mobile and Edge (È£ûÊ°®È´òÊÄßËÉΩÊ∑±Â∫¶Â≠¶‰π†Á´Ø‰æßÊé®ÁêÜÂºïÊìéÔºâ - https://github.com/PaddlePaddle/Paddle-Lite
tsotchke/eshkol: High-Performance LISP-like language for Scientific Computing and AI written in C - https://github.com/tsotchke/eshkol
AnotiaWang/deep-research-web-ui: (Supports DeepSeek R1) An AI-powered research assistant that performs iterative, deep research on any topic by combining search engines, web scraping, and large language models. - https://github.com/AnotiaWang/deep-research-web-ui
efeslab/Nanoflow: A throughput-oriented high-performance serving framework for LLMs - https://github.com/efeslab/Nanoflow
interestingLSY/swiftLLM: A tiny yet powerful LLM inference system tailored for researching purpose. vLLM-equivalent performance with only 2k lines of code (2% of vLLM). - https://github.com/interestingLSY/swiftLLM
langdb/ai-gateway: Govern, Secure, and Optimize your AI Traffic. AI Gateway provides unified interface to all LLMs using OpenAI API format with a focus on performance and reliability. Built in Rust. - https://github.com/langdb/ai-gateway
Lightning-AI/litgpt: 20+ high-performance LLMs with recipes to pretrain, finetune and deploy at scale. - https://github.com/Lightning-AI/litgpt
lindb/lindb: LinDB is a scalable, high performance, high availability distributed time series database. - https://github.com/lindb/lindb
deepseek-ai/3FS:  A high-performance distributed file system designed to address the challenges of AI training and inference workloads.  - https://github.com/deepseek-ai/3FS
arinbjornk/llmtop: A system monitoring tool powered by LLMs that provides real-time insights about your system's performance - https://github.com/arinbjornk/llmtop
winfunc/deepclaude: A high-performance LLM inference API and Chat UI that integrates DeepSeek R1's CoT reasoning traces with Anthropic Claude models. - https://github.com/winfunc/deepclaude
superagent-ai/super-rag: Super performant RAG pipelines for AI apps. Summarization, Retrieve/Rerank and Code Interpreters in one simple API. - https://github.com/superagent-ai/super-rag
alibaba/rtp-llm: RTP-LLM: Alibaba's high-performance LLM inference engine for diverse applications. - https://github.com/alibaba/rtp-llm
Miyamura80/tinyAcceleratedEVM: A gymnax based EVM simulator written in the JAX machine learning framework. The idea is to write an EVM simulator that can be parallelized and gain significant performance boosts on the accelerated hardware such GPU/TPU.  - https://github.com/Miyamura80/tinyAcceleratedEVM
arcprize/arc-agi-benchmarking: Testing baseline LLMs performance across various models - https://github.com/arcprize/arc-agi-benchmarking
promptfoo/promptfoo: Test your prompts, agents, and RAGs. AI Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration. - https://github.com/promptfoo/promptfoo
vectorch-ai/ScaleLLM: A high-performance inference system for large language models, designed for production environments. - https://github.com/vectorch-ai/ScaleLLM
taichi-dev/taichi: Productive, portable, and performant GPU programming in Python. - https://github.com/taichi-dev/taichi
facebookresearch/fairscale: PyTorch extensions for high performance and large scale training. - https://github.com/facebookresearch/fairscale
facebookresearch/habitat-sim: A flexible, high-performance 3D simulator for Embodied AI research. - https://github.com/facebookresearch/habitat-sim
digma-ai/digma: üßë‚Äçüíªüî≠ Digma helps you fix performance issues in your code by automatically profiling the code execution. Using APMs to identify code bottlenecks, query problems and scalability issues takes time and effort - Digma automates all of that. Digma is free for developers - get it here: https://digma.ai/get-digma/ - https://github.com/digma-ai/digma
Jamesmallon1/solana-block-cacher: Solana Block Cacher is a high-performance, command-line interface (CLI) tool built in Rust. It is designed to efficiently pull blocks from the Solana blockchain, respecting the specified rate limits. This tool intelligently measures the user's connection speed and the rate limit to calculate the optimum number of threads for fetching blocks. - https://github.com/Jamesmallon1/solana-block-cacher
douglasrizzo/microrts: A small implementation of an RTS game, designed to perform AI research - https://github.com/douglasrizzo/microrts
jcwill415/Stock_Market_Data_Analysis: Scrape, analyze & visualize stock market data for the S&P500 using Python. Build a basic trading strategy using machine learning to assess company performance and determine buy, sell, hold. Read me & instructions available in Spanish. This is a working repo, with plans to expand the project from technical analysis to fundamental analysis.  - https://github.com/jcwill415/Stock_Market_Data_Analysis
Tencent/Forward: A library for high performance deep learning inference on NVIDIA GPUs.  - https://github.com/Tencent/Forward
googleapis/repo-automation-bots: A collection of bots, based on probot, for performing common maintenance tasks across the open-source repos managed by Google on GitHub. - https://github.com/googleapis/repo-automation-bots
mailgun/gubernator: High Performance Rate Limiting MicroService and Library - https://github.com/mailgun/gubernator
harveybc/gym-fx: Forex trading simulator environment for OpenAI Gym, observations contain the order status, performance and timeseries loaded from a CSV file containing rates and indicators. Work In Progress - https://github.com/harveybc/gym-fx
CR-Gjx/Suspicion-Agent: The implementation of "Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4" - https://github.com/CR-Gjx/Suspicion-Agent
katanemo/archgw: The smart edge and AI gateway for agents. Arch is a high-performance proxy server that handles the low-level work in building agents: like applying guardrails, routing prompts to the right agent, and unifying access to LLMs, etc. Natively designed to handle and process prompts, Arch helps you build agents faster. - https://github.com/katanemo/archgw
aidenybai/react-scan: Scan for React performance issues and eliminate slow renders in your app - https://github.com/aidenybai/react-scan
AyeshaUlde/Grain-Boundary-Analysis-in-Digital-Microstructures: Code for term project of High Performance Computing for Engineering Applications (AM5080) course taken at IIT Madras during Jan-May 2023 - https://github.com/AyeshaUlde/Grain-Boundary-Analysis-in-Digital-Microstructures
JaredP94/Distributed-Equi-Join: Performance evaluation of Phoenix++ and MPI + OpenMP equi-join models for processing big data - https://github.com/JaredP94/Distributed-Equi-Join
MohsenKoohi/LaganLighter: LaganLighter: Structure-Aware High-Performance Graph Algorithms - https://github.com/MohsenKoohi/LaganLighter
duongquangduc/Partial-Differential-Equation: This project is a part of my thesis focusing on researching and applying the general-purpose graphics processing unit (GPGPU) in high performance computing. In this project, I applied GPU Computing and the parallel programming model CUDA to solve the diffusion equation. - https://github.com/duongquangduc/Partial-Differential-Equation
Twilight-Dream-Of-Magic/museair-cpp: A high-performance, non-cryptographic hashing algorithm written in C++. MuseAir offers fast, efficient hashing optimized for large datasets, with competitive performance compared to other popular algorithms like WyHash and RapidHash. Cross-platform support with thorough benchmarking. - https://github.com/Twilight-Dream-Of-Magic/museair-cpp
rubenandrebarreiro/gpu-cuda-self-organising-maps: üß† üí° üìà A project based in High Performance Computing. This project was built using CUDA (Compute Unified Device Architecture), C++ (C Plus Plus), C, CMake and JetBrains CLion. The scenario of the project was a GPU-based implementation of the Self-Organising-Maps (S.O.M.) algorithm for Artificial Neural Networks (A.N.N.), with the support of CUDA (Compute Unified Device Architecture), using its offered parallel optimisations and tunings. The final goal of the project was to test the several GPU-based implementations of the algorithm against a given CPU-based implementation of the same algorithm and, evaluate and compare the overall performance (speedup, efficiency and cost). - https://github.com/rubenandrebarreiro/gpu-cuda-self-organising-maps
KhaledAshrafH/Riemann-Zeta: This repository contains an MPI program written in C that calculates the Riemann zeta function and evaluates its performance using MPI collective communication functions. The program approximates the value of Œ∂(3) with a given value of `s` (3 - Ap√©ry's constant). It calculates the runtime, speedup, and efficiency for different numbers of processes. - https://github.com/KhaledAshrafH/Riemann-Zeta
keichi/kEDM: A high-performance implementation of Empirical Dynamic Modeling (EDM) - https://github.com/keichi/kEDM
ICB-DCM/parPE: Parameter estimation for dynamical models using high-performance computing, batch and mini-batch optimizers, and dynamic load balancing. - https://github.com/ICB-DCM/parPE
sail-sg/envpool: C++-based high-performance parallel environment execution engine (vectorized env) for general RL environments. - https://github.com/sail-sg/envpool
corkymaigre/multithreading-benchmarks: Multi-threading Performance Benchmark  - https://github.com/corkymaigre/multithreading-benchmarks
devanlooches/rocketfetch: A WIP command line system information tool written with multithreading in rust for performance with toml file configuration. - https://github.com/devanlooches/rocketfetch
navining/Zeus: A high performance, cross-platform Internet Communication Engine. Developed with native socket API. Aim at handling millions of concurrent connections. - https://github.com/navining/Zeus
composewell/streamly: High performance, concurrent functional programming abstractions - https://github.com/composewell/streamly
tobegit3hub/serving: A flexible, high-performance serving system for machine learning models - https://github.com/tobegit3hub/serving
tobegit3hub/hplearn: High performance machine learning system - https://github.com/tobegit3hub/hplearn
palico-ai/palico-ai: Build, Improve Performance, and Productionize your LLM Application with an Integrated Framework - https://github.com/palico-ai/palico-ai
ai/size-limit: Calculate the real cost to run your JS app or lib to keep good performance. Show error in pull request if the cost exceeds the limit. - https://github.com/ai/size-limit
GraphIt-DSL/graphit: GraphIt - A High-Performance Domain Specific Language for Graph Analytics - https://github.com/GraphIt-DSL/graphit
rishi-raj-jain/astro-font: `astro-font` will automatically optimize your Custom Fonts, Local Fonts, Fonts over any CDN and Google fonts for performance. - https://github.com/rishi-raj-jain/astro-font
mlcommons/inference: Reference implementations of MLPerf‚Ñ¢ inference benchmarks - https://github.com/mlcommons/inference
Qiskit/qiskit-aer: Aer is a high performance simulator for quantum circuits that includes noise models - https://github.com/Qiskit/qiskit-aer
performant23/sage-against-the-machine: This project explores and implements various techniques and protocols using SageMath. It covers topics such as Elliptic Curve Diffie-Hellman (ECDH) key exchange, homomorphic encryption, secure multi-party computation (MPC), queueing theory analysis, and RSA cryptanalysis. - https://github.com/performant23/sage-against-the-machine
tayebiarasteh/federated_he: Federated learning with homomorphic encryption enables multiple parties to securely co-train artificial intelligence models in pathology and radiology, reaching state-of-the-art performance with privacy guarantees. - https://github.com/tayebiarasteh/federated_he
z1labs/Cypher: Cypher, FHE-EVM Layer is the core of the DeAI ecosystem, designed to optimize blockchain for AI applications. It integrates Fully Homomorphic Encryption (FHE) with Ethereum Virtual Machine (EVM) compatibility, allowing encrypted AI computation without sacrificing performance. - https://github.com/z1labs/Cypher
microsoft/private-benchmarking: A platform that enables users to perform private benchmarking of machine learning models. The platform facilitates the evaluation of models based on different trust levels between the model owners and the dataset owners. - https://github.com/microsoft/private-benchmarking
huawei-noah/bolt: Bolt is a deep learning library with high performance and heterogeneous flexibility. - https://github.com/huawei-noah/bolt
OAID/Tengine: Tengine is a lite, high performance, modular inference engine for embedded device  - https://github.com/OAID/Tengine
Tencent/ncnn: ncnn is a high-performance neural network inference framework optimized for the mobile platform - https://github.com/Tencent/ncnn
yamadashy/repomix: üì¶ Repomix is a powerful tool that packs your entire repository into a single, AI-friendly file. Perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more. - https://github.com/yamadashy/repomix
microsoft/onnxruntime: ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator - https://github.com/microsoft/onnxruntime
semanser/codel: ‚ú® Fully autonomous AI Agent that can perform complicated tasks and projects using terminal, browser, and editor. - https://github.com/semanser/codel
cairoeth/sp1-eof: EOF (EVM Object Format) performance benchmarks for the EVM & SP1  üèéÔ∏è - https://github.com/cairoeth/sp1-eof
man-group/ArcticDB: ArcticDB is a high performance, serverless DataFrame database built for the Python Data Science ecosystem. - https://github.com/man-group/ArcticDB
knadh/listmonk: High performance, self-hosted, newsletter and mailing list manager with a modern dashboard. Single binary app. - https://github.com/knadh/listmonk
Membrizard/PyVaporation: The solution for modelling pervaporation membrane performance based on experimental data - https://github.com/Membrizard/PyVaporation
Uminosachi/inpaint-anything: Inpaint Anything performs stable diffusion inpainting on a browser UI using masks from Segment Anything. - https://github.com/Uminosachi/inpaint-anything
Uminosachi/sd-webui-inpaint-anything: Inpaint Anything extension performs stable diffusion inpainting on a browser UI using masks from Segment Anything. - https://github.com/Uminosachi/sd-webui-inpaint-anything
airchains-network/svm-station: Streamlined Solana Virtual Machine Integration for High-Performance rollups. - https://github.com/airchains-network/svm-station
mlc-ai/web-llm: High-performance In-browser LLM Inference Engine  - https://github.com/mlc-ai/web-llm
apache/brpc: brpc is an Industrial-grade RPC framework using C++ Language, which is often used in high performance system such as Search, Storage, Machine learning, Advertisement, Recommendation etc. "brpc" means "better RPC". - https://github.com/apache/brpc
concurrencykit/ck: Concurrency primitives, safe memory reclamation mechanisms and non-blocking (including lock-free) data structures designed to aid in the research, design and implementation of high performance concurrent systems developed in C99+. - https://github.com/concurrencykit/ck
ponylang/ponyc: Pony is an open-source, actor-model, capabilities-secure, high performance programming language - https://github.com/ponylang/ponyc
GaijinEntertainment/daScript: daslang - high-performance statically strong typed scripting language - https://github.com/GaijinEntertainment/daScript
tailcallhq/tailcall: High Performance GraphQL Runtime - https://github.com/tailcallhq/tailcall
robclu/leapfrog: Lock-free concurrent and single-threaded hash map implementations using Leapfrog probing. Currently the highest performance concurrent HashMap in Rust for certain use cases. - https://github.com/robclu/leapfrog
IceFireDB/redhub: High-performance Redis-Server multi-threaded framework, based on rawepoll model. - https://github.com/IceFireDB/redhub
tradingview/lightweight-charts: Performant financial charts built with HTML5 canvas - https://github.com/tradingview/lightweight-charts
baidu/dperf: dperf: High-Performance Network Load Testing Tool Based on DPDK - https://github.com/baidu/dperf
Liu-xiandong/How_to_optimize_in_GPU: This is a series of GPU optimization topics. Here we will introduce  how to optimize the CUDA kernel in detail.  I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit. - https://github.com/Liu-xiandong/How_to_optimize_in_GPU
