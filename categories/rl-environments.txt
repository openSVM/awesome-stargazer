# RL ENVIRONMENTS (25 repositories)

GPUOpen-LibrariesAndSDKs/Schola: Schola is a plugin for enabling Reinforcement Learning (RL) in Unreal Engine. It provides tools to help developers create environments, define agents, and connect to python-based RL frameworks such as OpenAI Gym, RLlib or Stable Baselines 3 for training agents with RL. - https://github.com/GPUOpen-LibrariesAndSDKs/Schola
google-deepmind/open_spiel: OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games. - https://github.com/google-deepmind/open_spiel
xlang-ai/OSWorld: [NeurIPS 2024] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments - https://github.com/xlang-ai/OSWorld
solplayground/solana_gym: OpenAI Gym Environment for Trading on Solana blockchain - https://github.com/solplayground/solana_gym
KhoomeiK/LlamaGym: Fine-tune LLM agents with online reinforcement learning - https://github.com/KhoomeiK/LlamaGym
PufferAI/PufferLib: Simplifying reinforcement learning for complex game environments - https://github.com/PufferAI/PufferLib
Miyamura80/tinyAcceleratedEVM: A gymnax based EVM simulator written in the JAX machine learning framework. The idea is to write an EVM simulator that can be parallelized and gain significant performance boosts on the accelerated hardware such GPU/TPU.  - https://github.com/Miyamura80/tinyAcceleratedEVM
a16z-infra/JungleGym: An Open Source Playground with Agent Datasets and APIs for building and testing your own Autonomous Web Agents - https://github.com/a16z-infra/JungleGym
harveybc/gym-fx: Forex trading simulator environment for OpenAI Gym, observations contain the order status, performance and timeseries loaded from a CSV file containing rates and indicators. Work In Progress - https://github.com/harveybc/gym-fx
sail-sg/envpool: C++-based high-performance parallel environment execution engine (vectorized env) for general RL environments. - https://github.com/sail-sg/envpool
cocktailpeanut/fluxgym: Dead simple FLUX LoRA training UI with LOW VRAM support - https://github.com/cocktailpeanut/fluxgym
Yvictor/TradingGym: Trading and Backtesting environment for training reinforcement learning agent or simple rule base algo. - https://github.com/Yvictor/TradingGym
charlieroberts/wgsl_live: An environment for live coding fragment shaders using WGSL - https://github.com/charlieroberts/wgsl_live
ChuaCheowHuan/gym-continuousDoubleAuction: A custom MARL (multi-agent reinforcement learning) environment where multiple agents trade against one another (self-play) in a zero-sum continuous double auction. Ray [RLlib] is used for training. - https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction
AminHP/gym-anytrading: The most simple, flexible, and comprehensive OpenAI Gym trading environment (Approved by OpenAI Gym) - https://github.com/AminHP/gym-anytrading
barkerbg001/echo-valley: Echo Valley is a procedurally generated 3D environment built with WebGL and Three.js. It offers an expansive, evolving world for exploration and experimentation, showcasing procedural generation in 3D. Whether you're a developer or just love endless virtual spaces, Echo Valley is a captivating sandbox to explore. - https://github.com/barkerbg001/echo-valley
openai/retro: Retro Games in Gym - https://github.com/openai/retro
gavento/gamegym: A game theory framework with examples and algorithms - https://github.com/gavento/gamegym
nadavbh12/Retro-Learning-Environment: The Retro Learning Environment (RLE) -- a learning framework for AI - https://github.com/nadavbh12/Retro-Learning-Environment
pearl-core/pearl: Pearl is a lightweight package manager for automating reproducible environments between different systems (Linux and OSX). It can be used for dotfiles, plugins, programs and any form of code accessible via git. - https://github.com/pearl-core/pearl
marlinprotocol/oyster-serverless: Oyster Serverless is a cutting-edge, high-performance serverless computing platform designed to securely execute JavaScript (JS) and WebAssembly (WASM) code in a highly controlled environment. - https://github.com/marlinprotocol/oyster-serverless
InseeFrLab/onyxia: ðŸ”¬ Data science environment for k8s - https://github.com/InseeFrLab/onyxia
facebookresearch/CompilerGym: Reinforcement learning environments for compiler and program optimization tasks - https://github.com/facebookresearch/CompilerGym
e2b-dev/E2B: Open-source, secure environment with real-world tools for enterprise-grade agents. - https://github.com/e2b-dev/E2B
Reinforcement_Learning_gym: 3 repos
