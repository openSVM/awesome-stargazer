[← Previous: Llms Gpt Openai 2](llms-gpt-openai-2.txt) | [🏠 Back to README](../README.md) | [Next: Llms Opensource Models →](llms-opensource-models.txt)

---

# LLMS INFERENCE

**8 repositories**

---

## [PrimeIntellect-ai/prime-vllm](https://github.com/PrimeIntellect-ai/prime-vllm)

Modded vLLM to run pipeline parallelism over public networks

🔗 [https://github.com/PrimeIntellect-ai/prime-vllm](https://github.com/PrimeIntellect-ai/prime-vllm)

---

## [vllm-project/aibrix](https://github.com/vllm-project/aibrix)

Cost-efficient and pluggable Infrastructure components for GenAI inference

🔗 [https://github.com/vllm-project/aibrix](https://github.com/vllm-project/aibrix)

---

## [France-Travail/happy_vllm](https://github.com/France-Travail/happy_vllm)

A REST API for vLLM, production ready

🔗 [https://github.com/France-Travail/happy_vllm](https://github.com/France-Travail/happy_vllm)

---

## [JackYFL/awesome-VLLMs](https://github.com/JackYFL/awesome-VLLMs)

This repository collects papers on VLLM applications. We will update new papers irregularly.

🔗 [https://github.com/JackYFL/awesome-VLLMs](https://github.com/JackYFL/awesome-VLLMs)

---

## [interestingLSY/swiftLLM](https://github.com/interestingLSY/swiftLLM)

A tiny yet powerful LLM inference system tailored for researching purpose. vLLM-equivalent performance with only 2k lines of code (2% of vLLM).

🔗 [https://github.com/interestingLSY/swiftLLM](https://github.com/interestingLSY/swiftLLM)

---

## [vllm-project/vllm](https://github.com/vllm-project/vllm)

A high-throughput and memory-efficient inference and serving engine for LLMs

🔗 [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)

---

## [vllm-project/production-stack](https://github.com/vllm-project/production-stack)

vLLM’s reference system for K8S-native cluster-wide deployment with community-driven performance optimization

🔗 [https://github.com/vllm-project/production-stack](https://github.com/vllm-project/production-stack)

---

## [NetEase-Media/grps](https://github.com/NetEase-Media/grps)

Deep Learning Deployment Framework: Supports tf/torch/trt/trtllm/vllm and other NN frameworks. Support dynamic batching, and streaming modes. It is dual-language compatible with Python and C++, offering scalability, extensibility, and high performance. It helps users quickly deploy models and provide services through HTTP/RPC interfaces.

🔗 [https://github.com/NetEase-Media/grps](https://github.com/NetEase-Media/grps)

---


[← Previous: Llms Gpt Openai 2](llms-gpt-openai-2.txt) | [🏠 Back to README](../README.md) | [Next: Llms Opensource Models →](llms-opensource-models.txt)
